{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import random\n",
    "from time import localtime, strftime\n",
    "from scipy.stats import spearmanr,pearsonr\n",
    "import zipfile\n",
    "import gc\n",
    "import time\n",
    "# fixing random seed for reproducibility\n",
    "random.seed(210116270)\n",
    "np.random.seed(210116270)\n",
    "import warnings\n",
    "#suppress warnings like RunTime error\n",
    "#warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#Mean Pooling - Take attention mask into account for correct averaging\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "\n",
    "# Sentences we want sentence embeddings for\n",
    "sentences = ['This is an example sentence', 'Each sentence is converted']\n",
    "\n",
    "# Load model from HuggingFace Hub\n",
    "tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')\n",
    "model = AutoModel.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')\n",
    "\n",
    "# Tokenize sentences\n",
    "encoded_input = tokenizer(sentences, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "# Compute token embeddings\n",
    "with torch.no_grad():\n",
    "    model_output = model(**encoded_input)\n",
    "\n",
    "# Perform pooling\n",
    "sentence_embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "\n",
    "# Normalize embeddings\n",
    "sentence_embeddings = F.normalize(sentence_embeddings, p=2, dim=1)\n",
    "\n",
    "print(\"Sentence embeddings:\")\n",
    "print(sentence_embeddings.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForNextSentencePrediction: ['cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertForNextSentencePrediction from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForNextSentencePrediction from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForNextSentencePrediction\n",
    "import torch\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForNextSentencePrediction.from_pretrained('bert-base-uncased')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set= pd.read_csv(\"my_lists.csv\")\n",
    "trr_set=pd.read_excel(\"train.xlsx\")\n",
    "test_set = pd.read_excel(\"evaluation.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Reason</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6670</th>\n",
       "      <td>and for ipad, you can not sign in with apple</td>\n",
       "      <td>The issue is that you cannot sign in with Appl...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6671</th>\n",
       "      <td>the app starts downloading again plus it is to...</td>\n",
       "      <td>The app is too heavy and starts downloading ag...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6672</th>\n",
       "      <td>a great tool to connect and share with groups</td>\n",
       "      <td>The reason the issue happened is because the t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6673</th>\n",
       "      <td>i need to uninstall it and reinstall it</td>\n",
       "      <td>There was a problem with the installation.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6674</th>\n",
       "      <td>I would also love to be able to control remote...</td>\n",
       "      <td>The remote screen cannot be controlled from th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6675</th>\n",
       "      <td>please tell how to connect audio with bluetoot...</td>\n",
       "      <td>The audio is not connecting with the bluetooth...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6676</th>\n",
       "      <td>i can not turn on video in the meeting.</td>\n",
       "      <td>The user's computer may not have a webcam, or ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6677</th>\n",
       "      <td>and i do not know how to navigate the app.</td>\n",
       "      <td>The user is new to the app and does not know h...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6678</th>\n",
       "      <td>missing information is unfriendly</td>\n",
       "      <td>The issue happened because some information wa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6679</th>\n",
       "      <td>for example the taskbar goes black</td>\n",
       "      <td>The taskbar goes black because the computer is...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6680</th>\n",
       "      <td>none of my other movie apps have this problem</td>\n",
       "      <td>There could be a problem with the app itself, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6681</th>\n",
       "      <td>it takes a long time to connect to the tv via ...</td>\n",
       "      <td>The Chromecast is designed to connect to your ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6682</th>\n",
       "      <td>so basically when i try to add contacts it doe...</td>\n",
       "      <td>There could be a problem with the Contacts app...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Text  \\\n",
       "6670       and for ipad, you can not sign in with apple   \n",
       "6671  the app starts downloading again plus it is to...   \n",
       "6672      a great tool to connect and share with groups   \n",
       "6673            i need to uninstall it and reinstall it   \n",
       "6674  I would also love to be able to control remote...   \n",
       "6675  please tell how to connect audio with bluetoot...   \n",
       "6676            i can not turn on video in the meeting.   \n",
       "6677         and i do not know how to navigate the app.   \n",
       "6678                  missing information is unfriendly   \n",
       "6679                 for example the taskbar goes black   \n",
       "6680      none of my other movie apps have this problem   \n",
       "6681  it takes a long time to connect to the tv via ...   \n",
       "6682  so basically when i try to add contacts it doe...   \n",
       "\n",
       "                                                 Reason  Label  \n",
       "6670  The issue is that you cannot sign in with Appl...      1  \n",
       "6671  The app is too heavy and starts downloading ag...      1  \n",
       "6672  The reason the issue happened is because the t...      1  \n",
       "6673         There was a problem with the installation.      1  \n",
       "6674  The remote screen cannot be controlled from th...      1  \n",
       "6675  The audio is not connecting with the bluetooth...      1  \n",
       "6676  The user's computer may not have a webcam, or ...      1  \n",
       "6677  The user is new to the app and does not know h...      1  \n",
       "6678  The issue happened because some information wa...      1  \n",
       "6679  The taskbar goes black because the computer is...      1  \n",
       "6680  There could be a problem with the app itself, ...      1  \n",
       "6681  The Chromecast is designed to connect to your ...      1  \n",
       "6682  There could be a problem with the Contacts app...      1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set[6670:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=train_set.iloc[:,:2]\n",
    "n_train_label=list(train_set.iloc[:,2])\n",
    "n_train_c1=list(train_data.iloc[:,0])\n",
    "n_train_c2=list(train_data.iloc[:,1])\n",
    "eval_data=test_set.iloc[:,:2]\n",
    "eval_label=list(test_set.iloc[:,2])\n",
    "eval_c1=list(eval_data.iloc[:,0])\n",
    "eval_c2=list(eval_data.iloc[:,1])\n",
    "\n",
    "train_label=list(trr_set.iloc[:,2])\n",
    "train_c1=list(trr_set.iloc[:,0])\n",
    "train_c2=list(trr_set.iloc[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def pick_rand(i):\n",
    "    return random.choice(list(range(1, i-20)) + list(range(i+20, len(train_label))))\n",
    "\n",
    "for i in range(len(train_c1)):\n",
    "    n_train_c1.append(train_c1[i])\n",
    "    n_train_c2.append(train_c2[pick_rand(i)])\n",
    "    n_train_label.append(0)\n",
    "\n",
    "\n",
    "c = list(zip(n_train_c1, n_train_c2, n_train_label))\n",
    "\n",
    "random.shuffle(c)\n",
    "\n",
    "n_train_c1, n_train_c2, n_train_label = zip(*c)\n",
    "n_train_c1=list(n_train_c1)\n",
    "n_train_c2=list(n_train_c2)\n",
    "n_train_label=list(n_train_label)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import openai\n",
    "import pandas as pd\n",
    "from time import sleep\n",
    "\n",
    "# set up API key\n",
    "openai.api_key = \"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\"\n",
    "model_engine = \"text-davinci-002\"\n",
    "\n",
    "# load the dataset\n",
    "df = n_train_c1\n",
    "\n",
    "abn=[]\n",
    "\n",
    "# repeat the process multiple times to generate new data samples\n",
    "for i in range(500):\n",
    "    start_sent = df[pick_rand(i)]\n",
    "    n_train_c1.append(start_sent)\n",
    "    #print(start_sent)\n",
    "    prompt = f\"{start_sent}\\n Generate some reason as to why issue in the previous sentence happened in about 10 words: \\n\"\n",
    "    response = openai.Completion.create(\n",
    "        engine=model_engine,\n",
    "        prompt=prompt,\n",
    "        max_tokens=50,\n",
    "        n=1,\n",
    "        stop=None,\n",
    "        temperature=0.5,\n",
    "    )\n",
    "    next_sent = response.choices[0].text.strip()\n",
    "    n_train_c2.append(next_sent)\n",
    "    n_train_label.append(1.01)\n",
    "    sleep(1)\n",
    "\n",
    "#abn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8744, 8744, 8744)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(n_train_c2),len(n_train_c1),len(n_train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(n_train_c1, n_train_c2, return_tensors='pt', max_length=512, truncation=True, padding='max_length')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs['labels'] = torch.LongTensor([n_train_label]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.labels[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ASSDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "    def __getitem__(self, idx):\n",
    "        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "    def __len__(self):\n",
    "        return len(self.encodings.input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ASSDataset(inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = torch.utils.data.DataLoader(dataset, batch_size=4, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForNextSentencePrediction(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (cls): BertOnlyNSPHead(\n",
       "    (seq_relationship): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "# and move our model over to the selected device\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Adafactor\n",
    "\n",
    "# activate training mode\n",
    "model.train()\n",
    "# initialize optimizer\n",
    "# AdamW(model.parameters(), lr=5e-7)\n",
    "optim =Adafactor(\n",
    "    model.parameters(),\n",
    "    lr=1e-5,\n",
    "    eps=(1e-30, 1e-3),\n",
    "    clip_threshold=1.0,\n",
    "    decay_rate=-0.8,\n",
    "    beta1=None,\n",
    "    weight_decay=0.0,\n",
    "    relative_step=False,\n",
    "    scale_parameter=False,\n",
    "    warmup_init=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2186 [00:00<?, ?it/s]<ipython-input-12-1bdca067cfb3>:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "Epoch 0: 100%|██████████| 2186/2186 [15:49<00:00,  2.30it/s, loss=2.24]    \n",
      "Epoch 1: 100%|██████████| 2186/2186 [15:49<00:00,  2.30it/s, loss=0.000269]\n",
      "Epoch 2: 100%|██████████| 2186/2186 [15:51<00:00,  2.30it/s, loss=0.00241] \n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm  # for our progress bar\n",
    "torch.cuda.empty_cache()\n",
    "epochs = 3\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # setup loop with TQDM and dataloader\n",
    "    loop = tqdm(loader, leave=True)\n",
    "    for batch in loop:\n",
    "        # initialize calculated gradients (from prev step)\n",
    "        optim.zero_grad()\n",
    "        # pull all tensor batches required for training\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        token_type_ids = batch['token_type_ids'].to(device)\n",
    "        labels_1 = batch['labels'].to(device)\n",
    "        # process\n",
    "        outputs = model(input_ids, attention_mask=attention_mask,\n",
    "                        token_type_ids=token_type_ids,\n",
    "                        labels=labels_1)\n",
    "        # extract loss\n",
    "        loss = outputs.loss\n",
    "        # calculate loss for every parameter that needs grad update\n",
    "        loss.backward()\n",
    "        # update parameters\n",
    "        optim.step()\n",
    "        # print relevant info to progress bar\n",
    "        loop.set_description(f'Epoch {epoch}')\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "\n",
    "\n",
    "model.save_pretrained('./saved_model/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([3578.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "        5422.]),\n",
       " array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions=[]\n",
    "\n",
    "for i in range(len(eval_c1)):\n",
    "    batch = tokenizer(eval_c1[i], eval_c2[i], return_tensors=\"pt\", max_length=512, truncation=True, padding='max_length')\n",
    "    input_ids = batch['input_ids'].to(device)\n",
    "    attention_mask = batch['attention_mask'].to(device)\n",
    "    token_type_ids = batch['token_type_ids'].to(device)\n",
    "    outputs = model(input_ids, attention_mask=attention_mask,token_type_ids=token_type_ids)\n",
    "    logits = outputs.logits\n",
    "    if logits[0, 0] > logits[0, 1]:\n",
    "        predictions.append(0)\n",
    "    else: predictions.append(1)\n",
    "\n",
    "plt.hist(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1\n",
      "1 0\n",
      "1 0\n",
      "0 0\n",
      "0 0\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "0 0\n",
      "1 0\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):print(abs(np.array(predictions))[i],eval_label[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_te=predictions#abs(np.array(predictions)-1)\n",
    "labels_test=eval_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6472222222222223\n",
      "Precision: 0.48395426042050904\n",
      "Recall: 0.874375208263912\n",
      "F1-Score: 0.6230559183188887\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy:', accuracy_score(labels_test,preds_te))\n",
    "print('Precision:', precision_score(labels_test,preds_te))\n",
    "print('Recall:', recall_score(labels_test,preds_te))\n",
    "print('F1-Score:', f1_score(labels_test,preds_te))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3201, 2798],\n",
       "       [ 377, 2624]], dtype=int64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(labels_test,preds_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: the app does not work because it will not let me enter my meeting and it says i do not have internet and if i have\n",
      "r: want to enter meetings\n",
      "true label 0, predicted 1\n",
      "-------------------\n",
      "t: thanks for fixing the audio issues.\n",
      "r: sound stopped working\n",
      "true label 0, predicted 1\n",
      "-------------------\n",
      "t: hotstar requests recurring payment, and there is no option to limit it\n",
      "r: hotstar user experience is bad\n",
      "true label 0, predicted 1\n",
      "-------------------\n",
      "t: if you want to watch a single episode/film in 1 go it works.\n",
      "r: want to be able to select episodes\n",
      "true label 0, predicted 1\n",
      "-------------------\n",
      "t: i can not adjust anything on my pc either.\n",
      "r: unable to work on any device\n",
      "true label 0, predicted 1\n",
      "-------------------\n",
      "t: on tablet, computer and pc no worries..\n",
      "r: unable to use on tablet\n",
      "true label 0, predicted 1\n",
      "-------------------\n",
      "t: but only on chromebooks but for apple stuff it works fine do not get this on chrome\n",
      "r: app is bad on chromebook\n",
      "true label 0, predicted 1\n",
      "-------------------\n",
      "t: good app but imdb rating not available this is very bad part of this app\n",
      "r: app is not good\n",
      "true label 0, predicted 1\n",
      "-------------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(110,140):\n",
    "    if (preds_te[i]>labels_test[i]):\n",
    "        print('t:',eval_c1[i])\n",
    "        print('r:',eval_c2[i])\n",
    "        print('true label 0, predicted 1')\n",
    "        print('-------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: so i uninstalled it, we should review the mobile application\n",
      "r: want to delete the app\n",
      "true label 1, predicted 0\n",
      "-------------------\n",
      "t: the app will not even load and i even paid for a subscription. disappointed and dissatisfied\n",
      "r: unable to use app\n",
      "true label 1, predicted 0\n",
      "-------------------\n",
      "t: i liked this app because when we want to download a series or movie you do not have to pay, it is free, that is why i loved this app\n",
      "r: good for watching movies and serials\n",
      "true label 1, predicted 0\n",
      "-------------------\n",
      "t: i can not cancel my subscription it throws it to google\n",
      "r: unable to unsubscribe\n",
      "true label 1, predicted 0\n",
      "-------------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(130,180):\n",
    "    if (preds_te[i]<labels_test[i]):\n",
    "        print('t:',eval_c1[i])\n",
    "        print('r:',eval_c2[i])\n",
    "        print('true label 1, predicted 0')\n",
    "        print('-------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
