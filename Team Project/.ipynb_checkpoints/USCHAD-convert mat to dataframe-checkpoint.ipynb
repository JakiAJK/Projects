{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "e-0u4x31yO-B"
   },
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import re\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "import sklearn.preprocessing as preprocessing\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Bidirectional\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import *\n",
    "\n",
    "#ZeroPadding3D\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.ops.numpy_ops import np_config\n",
    "np_config.enable_numpy_behavior()\n",
    "from tensorflow.keras import layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "from pyts.image import GramianAngularField\n",
    "from pyts.image import MarkovTransitionField\n",
    "from pyts.image import RecurrencePlot\n",
    "import shutil\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 3052951066440532673\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "-Qkg5NKTElXC"
   },
   "outputs": [],
   "source": [
    "top = \"C:\\\\Users\\\\jagat\\\\Desktop\\\\Masters\\\\Team Project/USC-HAD/USC-HAD/USC-HAD/\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1647298882801,
     "user": {
      "displayName": "louis w",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03511776485429477586"
     },
     "user_tz": 0
    },
    "id": "N9RfgHr4N81o",
    "outputId": "8e3b846a-a3c2-4104-d929-b082991eeddc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "840\n"
     ]
    }
   ],
   "source": [
    "df_num = 0\n",
    "for root, dirs, files in os.walk(top, topdown=True):\n",
    "  for file in files:\n",
    "    if '.mat' in file:\n",
    "      df_num += 1\n",
    "print(df_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n",
      "2.6.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "tf.test.is_built_with_cuda()\n",
    "print(tf.version.VERSION)\n",
    "import sys\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "eKbrfS2XbEq7"
   },
   "outputs": [],
   "source": [
    "dataframe_list = []\n",
    "\n",
    "for root, dirs, files in os.walk(top, topdown=True):\n",
    "  # print('root:',root)\n",
    "  # print('dirs:',dirs)\n",
    "  # print('files:',files)\n",
    "  for file in files:\n",
    "    if '.mat' in file:\n",
    "      sensor_readings = []\n",
    "      acc_x,acc_y,acc_z,gyro_x,gyro_y,gyro_z = [],[],[],[],[],[]\n",
    "      D = loadmat(os.path.join(root, file))\n",
    "      popKeys = ['__header__', '__globals__','__version__','title','version','date','trial','sensor_location','sensor_orientation']\n",
    "      for k in popKeys:\n",
    "        D.pop(k)\n",
    "\n",
    "      sensor_readings.append(D['sensor_readings'])\n",
    "\n",
    "      for readings in sensor_readings[0]:\n",
    "        acc_x.append(readings[0]) \n",
    "        acc_y.append(readings[1])\n",
    "        acc_z.append(readings[2])\n",
    "        gyro_x.append(readings[3])\n",
    "        gyro_y.append(readings[4])\n",
    "        gyro_z.append(readings[5])\n",
    "\n",
    "      dict_sensor_readings = {'acc_x':acc_x, 'acc_y':acc_y, 'acc_z':acc_z, 'gyro_x':gyro_x, 'gyro_y':gyro_y, 'gyro_z':gyro_z}\n",
    "      data = pd.DataFrame(dict_sensor_readings)\n",
    "\n",
    "      pattern = r'^[0-9]*'\n",
    "      column_name = ['age', 'height', 'weight', 'subject', 'label']\n",
    "      heights = re.findall(pattern, D['height'][0])[0]\n",
    "      weights = re.findall(pattern, D['weight'][0])[0]\n",
    "      ages = D['age'][0]\n",
    "      subjects = D['subject'][0]\n",
    "      if D.get(\"activity_number\") is None:\n",
    "        activity_numbers = '404'\n",
    "      else:\n",
    "        activity_numbers = D['activity_number'][0]\n",
    "      values = [ages, heights, weights, subjects, activity_numbers]\n",
    "      zip_ = zip(column_name, values)\n",
    "      for col_name, value in zip_:\n",
    "        data[col_name] = value\n",
    "      \n",
    "      dataframe_list.append(data)\n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1647298905647,
     "user": {
      "displayName": "louis w",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03511776485429477586"
     },
     "user_tz": 0
    },
    "id": "4k5s6e-jElcS",
    "outputId": "15615828-5ff8-4288-aee7-f786d088ad71"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "840"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataframe_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "622Uq3lVEleq"
   },
   "outputs": [],
   "source": [
    "dataframe_final = {}\n",
    "for i in range(df_num):\n",
    "  dataframe_final[i] = dataframe_list[i]\n",
    "\n",
    "df_raw = pd.concat(dataframe_final.values(), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2062,
     "status": "ok",
     "timestamp": 1647302079512,
     "user": {
      "displayName": "louis w",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03511776485429477586"
     },
     "user_tz": 0
    },
    "id": "yqivvFJuqRZn",
    "outputId": "cea2abae-4d1d-49dd-de6a-55cccdf9a9a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2811490\n",
      "2809281\n"
     ]
    }
   ],
   "source": [
    "print(len(df_raw))\n",
    "df = df_raw[(df_raw.label != '404')]\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 213,
     "status": "ok",
     "timestamp": 1647298955473,
     "user": {
      "displayName": "louis w",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03511776485429477586"
     },
     "user_tz": 0
    },
    "id": "AVMxqNRajKzB",
    "outputId": "8e7ed8c8-2426-478e-833a-25b756aee1c9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc_x</th>\n",
       "      <th>acc_y</th>\n",
       "      <th>acc_z</th>\n",
       "      <th>gyro_x</th>\n",
       "      <th>gyro_y</th>\n",
       "      <th>gyro_z</th>\n",
       "      <th>age</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>subject</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.653698</td>\n",
       "      <td>0.711878</td>\n",
       "      <td>-0.423886</td>\n",
       "      <td>-0.203916</td>\n",
       "      <td>-0.309533</td>\n",
       "      <td>-0.464422</td>\n",
       "      <td>27</td>\n",
       "      <td>164</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.646831</td>\n",
       "      <td>0.708259</td>\n",
       "      <td>-0.420226</td>\n",
       "      <td>0.103647</td>\n",
       "      <td>-0.161285</td>\n",
       "      <td>-0.241990</td>\n",
       "      <td>27</td>\n",
       "      <td>164</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.650265</td>\n",
       "      <td>0.711878</td>\n",
       "      <td>-0.423886</td>\n",
       "      <td>0.069611</td>\n",
       "      <td>-0.108322</td>\n",
       "      <td>-0.162525</td>\n",
       "      <td>27</td>\n",
       "      <td>164</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.646831</td>\n",
       "      <td>0.711878</td>\n",
       "      <td>-0.423886</td>\n",
       "      <td>0.352995</td>\n",
       "      <td>0.220050</td>\n",
       "      <td>0.179550</td>\n",
       "      <td>27</td>\n",
       "      <td>164</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.643397</td>\n",
       "      <td>0.711878</td>\n",
       "      <td>-0.427546</td>\n",
       "      <td>0.279527</td>\n",
       "      <td>0.174251</td>\n",
       "      <td>0.142181</td>\n",
       "      <td>27</td>\n",
       "      <td>164</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      acc_x     acc_y     acc_z    gyro_x    gyro_y    gyro_z age height  \\\n",
       "0 -0.653698  0.711878 -0.423886 -0.203916 -0.309533 -0.464422  27    164   \n",
       "1 -0.646831  0.708259 -0.420226  0.103647 -0.161285 -0.241990  27    164   \n",
       "2 -0.650265  0.711878 -0.423886  0.069611 -0.108322 -0.162525  27    164   \n",
       "3 -0.646831  0.711878 -0.423886  0.352995  0.220050  0.179550  27    164   \n",
       "4 -0.643397  0.711878 -0.427546  0.279527  0.174251  0.142181  27    164   \n",
       "\n",
       "  weight subject label  \n",
       "0     43       1    10  \n",
       "1     43       1    10  \n",
       "2     43       1    10  \n",
       "3     43       1    10  \n",
       "4     43       1    10  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 221,
     "status": "ok",
     "timestamp": 1647301530449,
     "user": {
      "displayName": "louis w",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03511776485429477586"
     },
     "user_tz": 0
    },
    "id": "Dm7ImYUZyVj0",
    "outputId": "272dedff-5895-4d04-b0f5-7aef0d8f7eec"
   },
   "outputs": [],
   "source": [
    "df.head()\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 550
    },
    "executionInfo": {
     "elapsed": 5100,
     "status": "ok",
     "timestamp": 1647301976576,
     "user": {
      "displayName": "louis w",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03511776485429477586"
     },
     "user_tz": 0
    },
    "id": "sSKCNR2pq7s2",
    "outputId": "278db6b7-f44c-4d90-ebae-ef6c0fbfe5be"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,9))\n",
    "plt.subplot(9,1,1)\n",
    "plt.plot(df[\"acc_x\"])\n",
    "plt.subplot(9,1,2)\n",
    "plt.plot(df[\"acc_y\"])\n",
    "plt.subplot(9,1,3)\n",
    "plt.plot(df[\"acc_z\"])\n",
    "plt.subplot(9,1,4)\n",
    "plt.plot(df[\"gyro_x\"])\n",
    "plt.subplot(9,1,5)\n",
    "plt.plot(df[\"gyro_y\"])\n",
    "plt.subplot(9,1,6)\n",
    "plt.plot(df[\"gyro_z\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XYM7c_-Lq7u2"
   },
   "outputs": [],
   "source": [
    "df_acc = pd.DataFrame(df, columns=['acc_x', 'acc_y', 'acc_z'])\n",
    "print(df_acc.head())\n",
    "df_gyro = pd.DataFrame(df, columns=['gyro_x', 'gyro_y', 'gyro_z'])\n",
    "print(df_gyro.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply median filter with filter length 5.\n",
    "df_med_acc = df_acc.rolling(window=5, center=True, min_periods=1).median()\n",
    "df_med_gyro = df_gyro.rolling(window=5, center=True, min_periods=1).median()\n",
    "\n",
    "# Plot acceleration data every 256 readings (2.56 sec) with median filter\n",
    "f, ax = plt.subplots(2, 4, figsize=(22, 8))\n",
    "ax = ax.flatten()\n",
    "for i in range(8):\n",
    "    for axis in ['acc_x', 'acc_y', 'acc_z']:\n",
    "        ax[i].plot(df_med_acc.iloc[i*2000:i*2000+256][axis].values, label=axis, linewidth=0.7)\n",
    "    ax[i].set_title(f\"Median filtered acceleration data within {i*2000}-{i*2000+256}\")\n",
    "    ax[i].legend(loc='lower left')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Plot raw gyroscope data (100Hz) every 256 readings (2.56 sec) with median filter\n",
    "f, ax = plt.subplots(2, 4, figsize=(22, 8))\n",
    "ax = ax.flatten()\n",
    "for i in range(8):\n",
    "    for axis in ['gyro_x', 'gyro_y', 'gyro_z']:\n",
    "        ax[i].plot(df_med_gyro.iloc[i*2000:i*2000+256][axis].values, label=axis, linewidth=0.7)\n",
    "    ax[i].set_title(f\"Median filtered gyroscope data within {i*2000}-{i*2000+256}\")\n",
    "    ax[i].legend(loc='lower left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply 3rd order low pass Butterworth filter with a corner frequency of 20 Hz.\n",
    "from scipy import signal\n",
    "fs = 50  # sampling frequency\n",
    "fc = 20  # cutoff frequency\n",
    "\n",
    "w = fc / (fs / 2)  # Normalize the frequency\n",
    "b, a = signal.butter(3, w, 'low')  # 3rd order low pass Butterworth filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_acc_med_but = pd.DataFrame(signal.filtfilt(b, a, df_med_acc, axis=0), columns=['acc_x', 'acc_y', 'acc_z'])\n",
    "df_gyro_med_but = pd.DataFrame(signal.filtfilt(b, a, df_med_gyro, axis=0), columns=['gyro_x', 'gyro_y', 'gyro_z'])\n",
    "\n",
    "# Plot acceleration data within 256 readings (2.56 sec) with median filter & Butterworth filter\n",
    "f, ax = plt.subplots(2, 4, figsize=(22, 8))\n",
    "ax = ax.flatten()\n",
    "for i in range(8):\n",
    "    for axis in ['acc_x', 'acc_y', 'acc_z']:\n",
    "        ax[i].plot(df_acc_med_but.iloc[i*2000:i*2000+256][axis].values, label=axis, linewidth=0.7)\n",
    "    ax[i].set_title(f\"Median & Butterworth filtered within {i*2000}-{i*2000+256}\")\n",
    "    ax[i].legend(loc='lower left')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Plot raw gyroscope data (100Hz) within 256 readings (2.56 sec) with median filter & Butterworth filter\n",
    "f, ax = plt.subplots(2, 4, figsize=(22, 8))\n",
    "ax = ax.flatten()\n",
    "for i in range(8):\n",
    "    for axis in ['gyro_x', 'gyro_y', 'gyro_z']:\n",
    "        ax[i].plot(df_gyro_med_but.iloc[i*2000:i*2000+256][axis].values, label=axis, linewidth=0.7)\n",
    "    ax[i].set_title(f\"Median & Butterworth filtered within {i*2000}-{i*2000+256}\")\n",
    "    ax[i].legend(loc='lower left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the magnitude of three-dimensional signals using the Euclidean norm.\n",
    "from numpy.linalg import norm\n",
    "\n",
    "acc_med_but_mag = norm(df_acc_med_but, ord=2, axis=1)\n",
    "gyro_med_but_mag = norm(df_gyro_med_but, ord=2, axis=1)\n",
    "\n",
    "print(acc_med_but_mag.shape)\n",
    "print(gyro_med_but_mag.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 256\n",
    "dt = 0.01  # 100Hz\n",
    "t = np.arange(0, N*dt, dt)  # time axis\n",
    "freq = np.linspace(0, 1.0 / dt, N)  # frequency axis\n",
    "win = np.hamming(N)  # hamming window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot with hamming\n",
    "f, ax = plt.subplots(2, 4, figsize=(22, 8))\n",
    "ax = ax.flatten()\n",
    "for i in range(8):\n",
    "    df_acc_fft = pd.DataFrame(columns=['acc_x', 'acc_y', 'acc_z'])\n",
    "    \n",
    "    for axis in ['acc_x', 'acc_y', 'acc_z']:\n",
    "        df_acc_fft[axis] = df_acc_med_but.iloc[i*256:i*256+256][axis] * win\n",
    "    \n",
    "    F = np.fft.fft(df_acc_fft, axis=0)\n",
    "    F = pd.DataFrame(F, columns=['acc_x', 'acc_y', 'acc_z'])\n",
    "    \n",
    "    F = F[:N//2+1]\n",
    "\n",
    "    # Calculare amplitude spectrum\n",
    "    Amp_acc = np.abs(F)\n",
    "    Amp_acc = pd.DataFrame(Amp_acc, columns=['acc_x', 'acc_y', 'acc_z'])\n",
    "    \n",
    "    Amp_acc = Amp_acc / N * 2\n",
    "    Amp_acc.iloc[0] = Amp_acc.iloc[0] / 2\n",
    "        \n",
    "    for axis in ['acc_x', 'acc_y', 'acc_z']:\n",
    "        ax[i].plot(Amp_acc[axis].values, label=axis, linewidth=0.7)\n",
    "        \n",
    "    ax[i].set_title(f\"Acceleration signal within {i*2000}-{i*2000+256}\")\n",
    "    ax[i].legend(loc='upper right')\n",
    "\n",
    "# Plot with hamming\n",
    "f, ax = plt.subplots(2, 4, figsize=(22, 8))\n",
    "ax = ax.flatten()\n",
    "for i in range(8):\n",
    "    df_gyro_fft = pd.DataFrame(columns=['gyro_x', 'gyro_y', 'gyro_z'])\n",
    "    \n",
    "    for axis in ['gyro_x', 'gyro_y', 'gyro_z']:\n",
    "        df_gyro_fft[axis] = df_gyro_med_but.iloc[i*256:i*256+256][axis] * win\n",
    "    \n",
    "    F = np.fft.fft(df_gyro_fft, axis=0)\n",
    "    F = pd.DataFrame(F, columns=['gyro_x', 'gyro_y', 'gyro_z'])\n",
    "    \n",
    "    F = F[:N//2+1]\n",
    "\n",
    "    # Calculare amplitude spectrum\n",
    "    Amp_gyro = np.abs(F)\n",
    "    Amp_gyro = pd.DataFrame(Amp_gyro, columns=['gyro_x', 'gyro_y', 'gyro_z'])\n",
    "    \n",
    "    Amp_gyro = Amp_gyro / N * 2\n",
    "    Amp_gyro.iloc[0] = Amp_gyro.iloc[0] / 2\n",
    "        \n",
    "    for axis in ['gyro_x', 'gyro_y', 'gyro_z']:\n",
    "        ax[i].plot(Amp_gyro[axis].values, label=axis, linewidth=0.7)\n",
    "        \n",
    "    ax[i].set_title(f\"Acceleration signal within {i*2000}-{i*2000+256}\")\n",
    "    ax[i].legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def window_segments_label_segments(df_data, windows, steps):\n",
    "  num_features = 6\n",
    "  window_segments = []\n",
    "  label_segments = []\n",
    "\n",
    "  for i in range(0, len(df_data)-windows, steps):\n",
    "    acc_x = df_data['acc_x'].values[i: i+windows]\n",
    "    acc_y = df_data['acc_y'].values[i: i+windows]\n",
    "    acc_z = df_data['acc_z'].values[i: i+windows]\n",
    "    gyro_x = df_data['gyro_x'].values[i: i+windows]\n",
    "    gyro_y = df_data['gyro_y'].values[i: i+windows]\n",
    "    gyro_z = df_data['gyro_z'].values[i: i+windows]\n",
    "    _label = df_data['label'].values[i: i+windows]\n",
    "    label = Counter(_label).most_common()[0][0]\n",
    "    window_segments.append([acc_x,acc_y,acc_z,gyro_x,gyro_y,gyro_z])\n",
    "    label_segments.append(label)\n",
    "\n",
    "  window_segments_reshape = np.asarray(window_segments, dtype= np.float32).transpose(0,2,1)#(-1, windows, num_features)\n",
    "  label_segments = np.asarray(label_segments)\n",
    "\n",
    "  return window_segments_reshape, label_segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 50% overlap\n",
    "windows = 128\n",
    "steps = 64\n",
    "X_fin, y_fin = window_segments_label_segments(df, windows, steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(X_fin))\n",
    "print(len(X_fin[0]))\n",
    "print(X_fin.shape)\n",
    "print(X_fin[0].shape)\n",
    "print(y_fin.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(X_fin[0][:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tr = to_categorical(y_fin)\n",
    "final_Y = np.delete(y_tr,0,1)\n",
    "final_Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "rand_indices= np.random.permutation(X_fin.shape[0])\n",
    "X_fin= X_fin[rand_indices]\n",
    "final_Y= final_Y[rand_indices]\n",
    "\n",
    "#80,20 split\n",
    "split= int(0.5*final_Y.shape[0])\n",
    "train_split= rand_indices[:split]\n",
    "test_split= rand_indices[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train= X_fin[train_split]\n",
    "X_test= X_fin[test_split]\n",
    "Y_train= final_Y[train_split]\n",
    "Y_test= final_Y[test_split]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, Y_train.shape, X_test.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graphs(history):\n",
    "    train_acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    plt.plot(train_acc, 'C0', label='train')\n",
    "    plt.plot(val_acc, 'C1', label='test')\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Accuracy\") \n",
    "    plt.title(\"Epoch vs Accuracy\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    train_acc = history.history['loss']\n",
    "    val_acc = history.history['val_loss']\n",
    "    plt.plot(train_acc, 'C0', label='train')\n",
    "    plt.plot(val_acc, 'C1', label='test')\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\") \n",
    "    plt.title(\"Epoch vs Loss\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def calc_scores(history):\n",
    "    train_acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    return len(train_acc),train_acc[-1]*100,val_acc[-1]*100\n",
    "\n",
    "scores=np.zeros(shape=(7,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_base= X_train.reshape(-1,32,24) #(-1,X_train.shape[1]*X_train.shape[2])\n",
    "X_test_base= X_test.reshape(-1,32,24) #reshape(-1,X_test.shape[1]*X_test.shape[2])\n",
    "x1,x2,x3= X_train_base.shape\n",
    "X_train_base=X_train_base.reshape(x1,x2,x3,1)\n",
    "X_test_base=X_test_base.reshape(x1,x2,x3,1)\n",
    "x1,x2,x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "np.random.seed(0) \n",
    "model_simple_CNN = models.Sequential(name = 'CNN_simple') \n",
    "\n",
    "#model_simple_CNN.build(input_shape=(x2, x3, 1))\n",
    "#model_simple_CNN.add(layers.ZeroPadding2D(padding=(2, 2)))\n",
    "model_simple_CNN.add(Conv2D(32,(5, 5), activation='selu', input_shape=(x2, x3, 1)))\n",
    "model_simple_CNN.add(Dropout(0.6))\n",
    "model_simple_CNN.add(BatchNormalization())\n",
    "model_simple_CNN.add(MaxPooling2D((2,2)))\n",
    "model_simple_CNN.add(layers.ZeroPadding2D(padding=(1, 1)))\n",
    "model_simple_CNN.add(Conv2D(64,(3, 3), activation='selu'))\n",
    "model_simple_CNN.add(Dropout(0.6))\n",
    "model_simple_CNN.add(BatchNormalization())\n",
    "model_simple_CNN.add(layers.ZeroPadding2D(padding=(1, 1)))\n",
    "model_simple_CNN.add(Conv2D(16,(3, 3), activation='selu'))\n",
    "model_simple_CNN.add(Dropout(0.6))\n",
    "model_simple_CNN.add(BatchNormalization())\n",
    "model_simple_CNN.add(layers.Flatten())\n",
    "#model_simple_CNN.add(layers.Dense(3072, activation='relu'))\n",
    "model_simple_CNN.add(Dropout(0.6))\n",
    "model_simple_CNN.add(layers.Dense(1536, activation='relu'))\n",
    "model_simple_CNN.add(Dropout(0.6))\n",
    "model_simple_CNN.add(layers.Dense(12, activation='softmax'))\n",
    "\n",
    "\n",
    "print(model_simple_CNN.summary())\n",
    "model_simple_CNN.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "LOG_DIR = os.path.join(os.getcwd(), 'logs')\n",
    "\n",
    "os.chdir(os.getcwd())\n",
    "\n",
    "tb = TensorBoard(LOG_DIR)\n",
    "\n",
    "weights_dir = 'weights/' + model_simple_CNN.name + \\\n",
    "            '-{epoch:02d}-{loss:.2f}'\n",
    "chkpt = ModelCheckpoint(filepath=weights_dir, monitor='loss', save_best_only=True, save_weights_only=True, mode='auto', save_freq=1)\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_acc', min_delta=0, patience=3)\n",
    "\n",
    "\n",
    "history = model_simple_CNN.fit(X_train_base, Y_train , epochs=15, \n",
    "                    validation_data=(X_test_base, Y_test ), callbacks=[tb, chkpt])\n",
    "\n",
    "plot_graphs(history)\n",
    "scores[0,:]=calc_scores(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "model_LSTM = Sequential(name = 'LSTM')\n",
    "model_LSTM.add(LSTM(512, recurrent_dropout=0.5, input_shape=(None, X_train.shape[2]))) \n",
    "model_LSTM.add(Dense(100, activation='relu'))\n",
    "model_LSTM.add(Dropout(0.5))\n",
    "model_LSTM.add(BatchNormalization())\n",
    "model_LSTM.add(Dense(12, activation='softmax'))\n",
    "model_LSTM.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=5e-4), metrics=['accuracy'])\n",
    "print(model_LSTM.summary())\n",
    "\n",
    "LOG_DIR = os.path.join(os.getcwd(), 'logs')\n",
    "\n",
    "os.chdir(os.getcwd())\n",
    "\n",
    "tb = TensorBoard(LOG_DIR)\n",
    "\n",
    "weights_dir = 'weights/' + model_LSTM.name + \\\n",
    "            '-{epoch:02d}-{loss:.2f}'\n",
    "chkpt = ModelCheckpoint(filepath=weights_dir, monitor='accuracy', save_best_only=True, save_weights_only=True, mode='auto', save_freq=1)\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_acc', min_delta=0, patience=3)\n",
    "\n",
    "\n",
    "history = model_LSTM.fit(X_train, Y_train , epochs=15, \n",
    "                    validation_data=(X_test, Y_test ), callbacks=[tb, chkpt])\n",
    "\n",
    "plot_graphs(history)\n",
    "scores[1,:]=calc_scores(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "model_biLSTM = Sequential(name = 'bidirectional_LSTM')\n",
    "model_biLSTM.add(Bidirectional(LSTM(512, recurrent_dropout=0.5), input_shape=(None, X_train.shape[2])))\n",
    "model_biLSTM.add(Dense(100, activation='relu'))\n",
    "model_biLSTM.add(Dropout(0.5))\n",
    "model_biLSTM.add(BatchNormalization())\n",
    "model_biLSTM.add(Dense(12, activation='softmax'))\n",
    "model_biLSTM.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=1e-3), metrics=['accuracy'])\n",
    "print(model_biLSTM.summary())\n",
    "\n",
    "LOG_DIR = os.path.join(os.getcwd(), 'logs')\n",
    "\n",
    "os.chdir(os.getcwd())\n",
    "\n",
    "tb = TensorBoard(LOG_DIR)\n",
    "\n",
    "weights_dir = 'weights/' + model_biLSTM.name + \\\n",
    "            '-{epoch:02d}-{loss:.2f}'\n",
    "chkpt = ModelCheckpoint(filepath=weights_dir, monitor='accuracy', save_best_only=True, save_weights_only=True, mode='auto', save_freq=1)\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_acc', min_delta=0, patience=3)\n",
    "\n",
    "\n",
    "history = model_biLSTM.fit(X_train, Y_train , epochs=15,\n",
    "                    validation_data=(X_test, Y_test ), callbacks=[tb, chkpt])\n",
    "\n",
    "plot_graphs(history)\n",
    "scores[2,:]=calc_scores(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acv=X_train[0,:,3]\n",
    "plt.plot(acv)\n",
    "plt.show()\n",
    "factor=4\n",
    "k=int(len(acv)/factor)\n",
    "transformer1 = MarkovTransitionField(image_size=1/factor, n_bins=4)#,strategy='uniform')\n",
    "transformer2 = GramianAngularField(image_size=1/factor)\n",
    "transformer3 = RecurrencePlot()#threshold=0.5)\n",
    "transformer4 = RecurrencePlot()#threshold=10)\n",
    "p=transformer1.transform(acv.reshape(1,-1))\n",
    "q=transformer2.transform(acv.reshape(1,-1))\n",
    "r=transformer4.transform(acv.reshape(1,-1))\n",
    "print(p.shape)\n",
    "plt.imshow(p.reshape(k,k));\n",
    "plt.show()\n",
    "plt.imshow(q.reshape(k,k));\n",
    "plt.show()\n",
    "plt.imshow(r.reshape(factor*k,factor*k));\n",
    "plt.show()\n",
    "avg_filt=layers.AveragePooling2D((factor, factor))\n",
    "plt.imshow(avg_filt(r.reshape(1,len(acv),len(acv),1)).reshape(k,k));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "#suppress warnings like RunTime error\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_X_MTF(X):\n",
    "    Xp=np.zeros(shape=(X.shape[0],k,k,X.shape[2]), dtype=np.float32)\n",
    "    for i in range(X.shape[0]):\n",
    "        for j in range(X.shape[2]):\n",
    "            dt=X[i,:,j]\n",
    "            img=transformer1.transform(dt.reshape(1,-1))\n",
    "            Xp[i,:,:,j]=img\n",
    "    return Xp\n",
    "\n",
    "X_MTF_train=new_X_MTF(X_train)\n",
    "X_MTF_test=new_X_MTF(X_test)\n",
    "x1,x2,x3,x4= X_MTF_train.shape\n",
    "X_MTF_train=X_MTF_train.reshape(x1,x2,x3,x4,1)\n",
    "X_MTF_test=X_MTF_test.reshape(x1,x2,x3,x4,1)\n",
    "print(x1,x2,x3,x4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "model_MTF = models.Sequential()\n",
    "model_MTF.add(layers.Conv3D(10, (5, 5, 2), activation='selu', input_shape=(x2,x3, x4, 1)))#, 1)))\n",
    "model_MTF.add(BatchNormalization())\n",
    "model_MTF.add(layers.MaxPooling3D((2, 2, 1)))\n",
    "#model_MTF.add(Dropout(0.5))\n",
    "model_MTF.add(layers.ZeroPadding3D(padding=(2, 2, 1)))\n",
    "model_MTF.add(layers.Conv3D(20, (3, 3, 1), activation='selu'))\n",
    "#model_MTF.add(Dropout(0.5))\n",
    "model_MTF.add(layers.Conv3D(100, (4, 4, 1), activation='selu'))\n",
    "model_MTF.add(layers.Flatten())\n",
    "#model_MTF.add(Dropout(0.5))\n",
    "#model_MTF.add(layers.Dense(100, activation='relu'))\n",
    "#model_MTF.add(Dropout(0.5))\n",
    "model_MTF.add(layers.Dense(12, activation='softmax'))\n",
    "print(model_MTF.summary())\n",
    "\n",
    "model_MTF.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "LOG_DIR = os.path.join(os.getcwd(), 'logs')\n",
    "\n",
    "os.chdir(os.getcwd())\n",
    "\n",
    "tb = TensorBoard(LOG_DIR)\n",
    "\n",
    "weights_dir = 'weights/' + model_MTF.name + \\\n",
    "            '-{epoch:02d}-{loss:.2f}'\n",
    "chkpt = ModelCheckpoint(filepath=weights_dir, monitor='loss', save_best_only=True, save_weights_only=True, mode='auto', save_freq=1)\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_acc', min_delta=0, patience=3)\n",
    "\n",
    "history = model_MTF.fit(X_MTF_train, Y_train , epochs=15, \n",
    "                    batch_size=3, validation_data=(X_MTF_test, Y_test), callbacks=[tb, chkpt])\n",
    "\n",
    "plot_graphs(history)\n",
    "scores[3,:]=calc_scores(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_X_GAF(X):\n",
    "    Xp=np.zeros(shape=(X.shape[0],k,k,X.shape[2]), dtype=np.float32)\n",
    "    for i in range(X.shape[0]):\n",
    "        for j in range(X.shape[2]):\n",
    "            dt=X[i,:,j]\n",
    "            img=transformer2.transform(dt.reshape(1,-1))\n",
    "            Xp[i,:,:,j]=img\n",
    "    return Xp\n",
    "\n",
    "X_GAF_train=new_X_GAF(X_train)\n",
    "X_GAF_test=new_X_GAF(X_test)\n",
    "x1,x2,x3,x4= X_GAF_train.shape\n",
    "X_GAF_train=X_GAF_train.reshape(x1,x2,x3,x4,1)\n",
    "X_GAF_test=X_GAF_test.reshape(x1,x2,x3,x4,1)\n",
    "print(x1,x2,x3,x4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "model_GAF = models.Sequential()\n",
    "model_GAF.add(layers.Conv3D(10, (5, 5, 2), activation='selu', input_shape=(x2,x3, x4, 1)))\n",
    "model_GAF.add(BatchNormalization())\n",
    "model_GAF.add(layers.MaxPooling3D((2, 2, 1)))\n",
    "model_GAF.add(Dropout(0.5))\n",
    "model_GAF.add(layers.ZeroPadding3D(padding=(2, 2, 1)))\n",
    "model_GAF.add(layers.Conv3D(20, (3, 3, 1), activation='selu'))\n",
    "model_GAF.add(Dropout(0.5))\n",
    "model_GAF.add(layers.Conv3D(100, (4, 4, 1), activation='selu'))\n",
    "model_GAF.add(layers.Flatten())\n",
    "#model_GAF.add(Dropout(0.5))\n",
    "#model_GAF.add(layers.Dense(100, activation='relu'))\n",
    "#model_GAF.add(Dropout(0.5))\n",
    "model_GAF.add(layers.Dense(12, activation='softmax'))\n",
    "print(model_GAF.summary())\n",
    "\n",
    "model_GAF.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "LOG_DIR = os.path.join(os.getcwd(), 'logs')\n",
    "\n",
    "os.chdir(os.getcwd())\n",
    "\n",
    "tb = TensorBoard(LOG_DIR)\n",
    "\n",
    "weights_dir = 'weights/' + model_GAF.name + \\\n",
    "            '-{epoch:02d}-{loss:.2f}'\n",
    "chkpt = ModelCheckpoint(filepath=weights_dir, monitor='loss', save_best_only=True, save_weights_only=True, mode='auto', save_freq=1)\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_acc', min_delta=0, patience=3)\n",
    "\n",
    "history = model_GAF.fit(X_GAF_train, Y_train , epochs=15, \n",
    "                    batch_size=3, validation_data=(X_GAF_test, Y_test), callbacks=[tb, chkpt])\n",
    "\n",
    "plot_graphs(history)\n",
    "scores[4,:]=calc_scores(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_X_RP(X):\n",
    "    Xp=np.zeros(shape=(X.shape[0],k,k,X.shape[2]), dtype=np.float32)\n",
    "    for i in range(X.shape[0]):\n",
    "        for j in range(X.shape[2]):\n",
    "            dt=X[i,:,j]\n",
    "            if j<3:\n",
    "                img=transformer3.transform(dt.reshape(1,-1))\n",
    "            else:\n",
    "                img=transformer4.transform(dt.reshape(1,-1))\n",
    "            img=avg_filt(img.reshape(1,len(acv),len(acv),1)).reshape(k,k)\n",
    "            Xp[i,:,:,j]=img\n",
    "    return Xp\n",
    "\n",
    "X_RP_train=new_X_RP(X_train)\n",
    "X_RP_test=new_X_RP(X_test)\n",
    "x1,x2,x3,x4= X_RP_train.shape\n",
    "X_RP_train=X_RP_train.reshape(x1,x2,x3,x4,1)\n",
    "X_RP_test=X_RP_test.reshape(x1,x2,x3,x4,1)\n",
    "print(x1,x2,x3,x4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "model_RP = models.Sequential()\n",
    "model_RP.add(layers.Conv3D(10, (5, 5, 2), activation='selu', input_shape=(x2,x3, x4, 1)))\n",
    "model_RP.add(BatchNormalization())\n",
    "model_RP.add(layers.MaxPooling3D((2, 2, 1)))\n",
    "model_RP.add(Dropout(0.5))\n",
    "model_RP.add(layers.ZeroPadding3D(padding=(2, 2, 1)))\n",
    "model_RP.add(layers.Conv3D(20, (3, 3, 1), activation='selu'))\n",
    "model_RP.add(Dropout(0.5))\n",
    "model_RP.add(layers.Conv3D(100, (4, 4, 1), activation='selu'))\n",
    "model_RP.add(layers.Flatten())\n",
    "#model_RP.add(Dropout(0.5))\n",
    "#model_RP.add(layers.Dense(100, activation='relu'))\n",
    "#model_RP.add(Dropout(0.5))\n",
    "model_RP.add(layers.Dense(12, activation='softmax'))\n",
    "print(model_RP.summary())\n",
    "\n",
    "\n",
    "model_RP.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "LOG_DIR = os.path.join(os.getcwd(), 'logs')\n",
    "\n",
    "os.chdir(os.getcwd())\n",
    "\n",
    "tb = TensorBoard(LOG_DIR)\n",
    "\n",
    "weights_dir = 'weights/' + model_RP.name + \\\n",
    "            '-{epoch:02d}-{loss:.2f}'\n",
    "chkpt = ModelCheckpoint(filepath=weights_dir, monitor='loss', save_best_only=True, save_weights_only=True, mode='auto', save_freq=1)\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_acc', min_delta=0, patience=3)\n",
    "\n",
    "history = model_RP.fit(X_RP_train, Y_train , epochs=15, \n",
    "                    batch_size=3, validation_data=(X_RP_test, Y_test), callbacks=[tb, chkpt])\n",
    "\n",
    "plot_graphs(history)\n",
    "scores[5,:]=calc_scores(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_X_all(X):\n",
    "    Xp=np.zeros(shape=(X.shape[0],k,k,X.shape[2]*3), dtype=np.float32)\n",
    "    for i in range(X.shape[0]):\n",
    "        for j in range(X.shape[2]):\n",
    "            dt=X[i,:,j]\n",
    "            img1=transformer1.transform(dt.reshape(1,-1))\n",
    "            Xp[i,:,:,3*j]=img1\n",
    "            img2=transformer2.transform(dt.reshape(1,-1))\n",
    "            Xp[i,:,:,3*j+1]=img2\n",
    "            if j<3:\n",
    "                img3=transformer3.transform(dt.reshape(1,-1))\n",
    "            else:\n",
    "                img3=transformer4.transform(dt.reshape(1,-1))\n",
    "            img3=avg_filt(img3.reshape(1,len(acv),len(acv),1)).reshape(k,k)\n",
    "            Xp[i,:,:,3*j+2]=img3\n",
    "    return Xp\n",
    "\n",
    "X_all_img_train=new_X_all(X_train)\n",
    "X_all_img_test=new_X_all(X_test)\n",
    "x1,x2,x3,x4= X_all_img_train.shape\n",
    "X_all_img_train=X_all_img_train.reshape(x1,x2,x3,x4,1)\n",
    "X_all_img_test=X_all_img_test.reshape(x1,x2,x3,x4,1)\n",
    "print(x1,x2,x3,x4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv3D(10, (5, 5, 2), activation='selu', input_shape=(x2,x3, x4, 1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(layers.MaxPooling3D((2, 2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(layers.ZeroPadding3D(padding=(2, 2, 1)))\n",
    "model.add(layers.Conv3D(50, (3, 3, 3), activation='selu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(layers.Conv3D(10, (4, 4, 4), activation='selu'))\n",
    "model.add(layers.Flatten())\n",
    "#model.add(Dropout(0.5))\n",
    "#model.add(layers.Dense(1200, activation='selu'))\n",
    "#model.add(Dropout(0.5))\n",
    "#model.add(layers.Dense(120, activation='sigmoid'))\n",
    "model.add(layers.Dense(12, activation='softmax'))\n",
    "print(model.summary())\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "LOG_DIR = os.path.join(os.getcwd(), 'logs')\n",
    "\n",
    "os.chdir(os.getcwd())\n",
    "\n",
    "tb = TensorBoard(LOG_DIR)\n",
    "shutil.rmtree('/content/weights', ignore_errors=True)\n",
    "weights_dir = 'weights/' + model.name + \\\n",
    "            '-{epoch:02d}-{loss:.2f}'\n",
    "chkpt = ModelCheckpoint(filepath=weights_dir, monitor='loss', save_best_only=True, save_weights_only=True, mode='auto', save_freq=1)\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_acc', min_delta=0, patience=3)\n",
    "\n",
    "history = model.fit(X_all_img_train, Y_train , epochs=15, \n",
    "                    batch_size=3, validation_data=(X_all_img_test, Y_test), callbacks=[tb, chkpt])\n",
    "\n",
    "plot_graphs(history)\n",
    "scores[6,:]=calc_scores(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_all_img_test, Y_test)\n",
    "\n",
    "pred = np.argmax(model.predict(X_all_img_test), axis = -1)\n",
    "confusion = confusion_matrix(np.argmax(Y_test, axis = -1), pred)\n",
    "NUM_LABELS = 12\n",
    "\n",
    "f, axes = plt.subplots(1,1, figsize = (12,12))\n",
    "axes.set_xlabel('Actual')\n",
    "axes.set_ylabel('Predicted')\n",
    "axes.grid(False)\n",
    "axes.set_xticklabels(class_labels, rotation = 90)\n",
    "axes.set_yticklabels(class_labels)\n",
    "axes.set_yticks(list(range(NUM_LABELS)))\n",
    "axes.set_xticks(list(range(NUM_LABELS)))\n",
    "plt.imshow(confusion, cmap=plt.cm.Set2, interpolation='nearest')\n",
    "\n",
    "for i, cas in enumerate(confusion):\n",
    "    for j, count in enumerate(cas):\n",
    "        if count > 0:\n",
    "            xoff = .07 * len(str(count))\n",
    "            plt.text(j-xoff, i+.2, int(count), fontsize=12, color='black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "row_names=[\"CNN simple\",\"LSTM simple\",\"Bidirectional LSTM\",\"MTF image CNN\",\"GAF image CNN\",\"RP image CNN\",\"MTF+GAF+RP image CNN\"]\n",
    "column_names=[\"Epochs\",\"Training Accuracy %\",\"Test Accuracy %\"]\n",
    "Full_results= pd.DataFrame(scores, index=row_names, columns=column_names)\n",
    "Full_results"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNxUelIjkTsZGEmS1IkhokV",
   "collapsed_sections": [],
   "name": "USCHAD-convert mat to dataframe.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
